{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a76fc81",
   "metadata": {},
   "source": [
    "# nilmtkを用いた電力消費を分析する機械学習\n",
    "\n",
    "## 1. 準備\n",
    "インドで計測されたデータセットと田中の家で計測した3つの家電(冷蔵庫、テレビ、エアコン)のデータセットを用います。\n",
    "\n",
    "nilmtkの環境構築は済んでいるものとします。環境構築についてはhttps://docs.google.com/document/d/1lqsn3UlNLvOTVsLZisnizys29YpQzRTqvJiWQcEtpKg/edit?usp=sharing を参照してください。\n",
    "\n",
    "必要なもの\n",
    "- electricity_India\n",
    "- electricity_Tanaka\n",
    "- metadata_India\n",
    "- metadata_Tanaka\n",
    "\n",
    "新しくデータセットを作る場合にはelectricity_〇〇とmetadata_〇〇を1セット準備する必要があります。\n",
    "\n",
    "\n",
    "- electricity_India：iawe( https://iawe.github.io/ )から\"electricity.tar.gz\"をダウンロードします。ですが、このままだと全家電対象になってしまうので、ファイルを改変して家電を3つに限定しました。\n",
    "- electricity_Tanaka：田中の家で計測したデータです。\n",
    "- metadata_India:インドのデータセットの基本設定を記したものです。\n",
    "- metadata_Tanaka:田中家のデータセットの基本設定を記したものです。\n",
    "\n",
    "electricity_〇〇は1.csv～4.csv, labels.datがあります。1.csvが合計の電力、2.csvが冷蔵庫、3.csvがエアコン、4.csvがテレビです。ライブラリの仕様上計測日時をタイムスタンプに変更しています。labels.datに各csvファイルの家電の種類が書いてありますが、datファイルはなくても大丈夫なはずです。\n",
    "\n",
    "metadata_〇〇はcsvファイルをh5ファイルに変換するために必要な情報です。dataset.yml, meter_devices.yml, building〇.yml, があります。dataset.ymlはデータセットの製作者やデータを取った場所などの基本的な情報を入れます。meta_device.ymlには計測器の情報を入れます。building〇.ymlは建物の数だけ用意します。1個目の建物はbuilding1.yml、2個目の建物はbuilding2.ymlという風になります。building〇.ymlファイルには各家電の種類や親子関係などを記載します。この際家電につけたmeterの番号とcsvファイルの数字を一致させる必要があります。例えば冷蔵庫のデータを2.csvにいれてありますが、building1.ymlでは\"type: fridge, meters: [2]\"としてあります。説明が難しいので詳しい情報はhttps://nilm-metadata.readthedocs.io/en/latest/tutorial.html のexampleを見てください。\n",
    "\n",
    "ここから家電を増やしたい場合は\n",
    "①csvファイルを追加する\n",
    "②(datファイルも書き換える)\n",
    "③building〇.ymlを書き換える\n",
    "とすればよいです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1695e1f",
   "metadata": {},
   "source": [
    "## 2. CSVファイルとyamlファイルをh5ファイルに変換する\n",
    "まずは変換する関数を定義します。本当はインドのデータセットについてはライブラリを使えば一発なのですが、家電の種類を3つに揃えるためにライブラリを改造しました。\n",
    "electiricity_〇〇のフォルダが置いてある場所や家電の数によって一部コードを書き換えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5669b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk.measurement import LEVEL_NAMES\n",
    "from nilmtk.utils import check_directory_exists, get_datastore, get_module_directory\n",
    "from nilm_metadata import convert_yaml_to_hdf5\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "\n",
    "def reindex_fill_na(df, idx):\n",
    "    df_copy = deepcopy(df)\n",
    "    df_copy = df_copy.reindex(idx)\n",
    "\n",
    "    power_columns = [\n",
    "        x for x in df.columns if x[0] in ['power']]\n",
    "    non_power_columns = [x for x in df.columns if x not in power_columns]\n",
    "\n",
    "    for power in power_columns:\n",
    "        df_copy[power].fillna(0, inplace=True)\n",
    "    for measurement in non_power_columns:\n",
    "        df_copy[measurement].fillna(df[measurement].median(), inplace=True)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "column_mapping = {\n",
    "    'frequency': ('frequency', \"\"),\n",
    "    'voltage': ('voltage', \"\"),\n",
    "    'W': ('power', 'active'),\n",
    "    'energy': ('energy', 'apparent'),\n",
    "    'A': ('current', ''),\n",
    "    'reactive_power': ('power', 'reactive'),\n",
    "    'apparent_power': ('power', 'apparent'),\n",
    "    'power_factor': ('pf', ''),\n",
    "    'PF': ('pf', ''),\n",
    "    'phase_angle': ('phi', ''),\n",
    "    'VA': ('power', 'apparent'),\n",
    "    'VAR': ('power', 'reactive'),\n",
    "    'VLN': ('voltage', \"\"),\n",
    "    'V': ('voltage', \"\"),\n",
    "    'f': ('frequency', \"\")\n",
    "}\n",
    "\n",
    "TIMESTAMP_COLUMN_NAME = \"timestamp\"\n",
    "TIMEZONE = \"Asia/Tokyo\"\n",
    "START_DATETIME, END_DATETIME = '2023-01-08', '2023-01-09'\n",
    "FREQ = \"1T\"\n",
    "\n",
    "def convert_house(electricity_path, metadata_path, output_filename, format=\"HDF\"):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    iawe_path : str\n",
    "        The root path of the iawe dataset.\n",
    "    output_filename : str\n",
    "        The destination filename (including path and suffix).\n",
    "    \"\"\"\n",
    "\n",
    "    check_directory_exists(electricity_path)\n",
    "    idx = pd.date_range(start=START_DATETIME, end=END_DATETIME, freq=FREQ)\n",
    "    idx = idx.tz_localize('GMT').tz_convert(TIMEZONE)\n",
    "\n",
    "    # Open data store\n",
    "    store = get_datastore(output_filename, format, mode='w')\n",
    "\n",
    "    # Mains data\n",
    "    # rangeを変えることでcsvファイルを参照する数を変えます。\n",
    "    for chan in range(1, 5):\n",
    "        key = Key(building=1, meter=chan)\n",
    "        filename = join(electricity_path, \"%d.csv\" % chan)\n",
    "        print('Loading ', chan)\n",
    "        df = pd.read_csv(filename, dtype=np.float64, na_values='\\\\N')\n",
    "        df.drop_duplicates(subset=[\"timestamp\"], inplace=True)\n",
    "        df.index = pd.to_datetime(df.timestamp.values, unit='s', utc=True)\n",
    "        df = df.tz_convert(TIMEZONE)\n",
    "        df = df.drop(TIMESTAMP_COLUMN_NAME, 1)\n",
    "        df.columns = pd.MultiIndex.from_tuples(\n",
    "            [column_mapping[x] for x in df.columns],\n",
    "            names=LEVEL_NAMES\n",
    "        )\n",
    "        df = df.apply(pd.to_numeric, errors='ignore')\n",
    "        df = df.dropna()\n",
    "        df = df.astype(np.float32)\n",
    "        df = df.sort_index()\n",
    "        df = df.resample(\"1T\").mean()\n",
    "        df = reindex_fill_na(df, idx)\n",
    "        assert df.isnull().sum().sum() == 0\n",
    "        store.put(str(key), df)\n",
    "    store.close()\n",
    "    \n",
    "    convert_yaml_to_hdf5(metadata_dir, output_filename)\n",
    "\n",
    "    print(\"Done converting csv and yaml files to HDF5!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ca7e3",
   "metadata": {},
   "source": [
    "タイムゾーン、計測開始時と終了時(世界標準時なことに注意)など設定してh5ファイルに変換します。\n",
    "\n",
    "今回はzipファイルにh5ファイルを同封してあるので実際はこの作業は不要なのですが、一旦h5ファイルを消してみて動くか確認してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP_COLUMN_NAME = \"timestamp\"\n",
    "TIMEZONE = \"Asia/Tokyo\"\n",
    "START_DATETIME, END_DATETIME = '2023-01-08', '2023-01-09'\n",
    "FREQ = \"1T\"\n",
    "\n",
    "#自分のelectricity_○○とmetadata_〇〇が置いてあるフォルダのパスを参照してください。\n",
    "electricity_path = \"C:/Users/MEIP-users/nilmtk/electricity_Tanaka\"\n",
    "metadata_path = \"C:/Users/MEIP-users/nilmtk/metadata_Tanaka\"\n",
    "convert_house(electricity_path, metadata_path, \"data_Tanaka.h5\")\n",
    "\n",
    "\n",
    "TIMESTAMP_COLUMN_NAME = \"timestamp\"\n",
    "TIMEZONE = \"Asia/Kolkata\"\n",
    "START_DATETIME, END_DATETIME = '2013-07-13', '2013-08-04'\n",
    "FREQ = \"1T\"\n",
    "\n",
    "#自分のelectricity_○○とmetadata_〇〇が置いてあるフォルダのパスを参照してください。\n",
    "electricity_path = \"C:/Users/MEIP-users/nilmtk/electricity_India\"\n",
    "metadata_path = \"C:/Users/MEIP-users/nilmtk/metadata_India\"\n",
    "convert_house(electricity_path, metadata_path, \"data_India.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da2acd",
   "metadata": {},
   "source": [
    "## 3. 機械学習を実行する\n",
    "まずは学習データとテストデータをh5ファイルで指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk import DataSet\n",
    "from nilmtk.utils import print_dict\n",
    "\n",
    "#学習データとテストデータを指定\n",
    "train = DataSet('data_India.h5')\n",
    "test = DataSet('data_Tanaka.h5')\n",
    "#建物1の電力のデータだけ使う\n",
    "train_elec = train.buildings[1].elec\n",
    "test_elec = test.buildings[1].elec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b71b1",
   "metadata": {},
   "source": [
    "次に機械学習のモデルを作る関数を書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import time\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six import iteritems\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "import nilmtk.utils\n",
    "\n",
    "#使用する機械学習のアルゴリズムをインポートします。\n",
    "from nilmtk.legacy.disaggregate import CombinatorialOptimisation, FHMM\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def predict(clf, test_elec, sample_period, timezone):\n",
    "    pred = {}\n",
    "    gt= {}\n",
    "    \n",
    "    # \"ac_type\" varies according to the dataset used. \n",
    "    # Make sure to use the correct ac_type before using the default parameters in this code.    \n",
    "    for i, chunk in enumerate(test_elec.mains().load(physical_quantity = 'power', ac_type = 'active', sample_period=sample_period)):\n",
    "        chunk_drop_na = chunk.dropna()\n",
    "        pred[i] = clf.disaggregate_chunk(chunk_drop_na)\n",
    "        gt[i]={}\n",
    "\n",
    "        for meter in test_elec.submeters().meters:\n",
    "            # Only use the meters that we trained on (this saves time!)    \n",
    "            gt[i][meter] = next(meter.load(physical_quantity = 'power', ac_type = 'active', sample_period=sample_period))\n",
    "        gt[i] = pd.DataFrame({k:v.squeeze() for k,v in iteritems(gt[i]) if len(v)}, index=next(iter(gt[i].values())).index).dropna()\n",
    "        \n",
    "    # If everything can fit in memory\n",
    "    gt_overall = pd.concat(gt)\n",
    "    gt_overall.index = gt_overall.index.droplevel()\n",
    "    pred_overall = pd.concat(pred)\n",
    "    pred_overall.index = pred_overall.index.droplevel()\n",
    "\n",
    "    # Having the same order of columns\n",
    "    gt_overall = gt_overall[pred_overall.columns]\n",
    "    \n",
    "    #Intersection of index\n",
    "    gt_index_utc = gt_overall.index.tz_convert(\"UTC\")\n",
    "    pred_index_utc = pred_overall.index.tz_convert(\"UTC\")\n",
    "    common_index_utc = gt_index_utc.intersection(pred_index_utc)\n",
    "    \n",
    "    common_index_local = common_index_utc.tz_convert(timezone)\n",
    "    gt_overall = gt_overall.loc[common_index_local]\n",
    "    pred_overall = pred_overall.loc[common_index_local]\n",
    "    appliance_labels = [m for m in gt_overall.columns.values]\n",
    "    gt_overall.columns = appliance_labels\n",
    "    pred_overall.columns = appliance_labels\n",
    "    return gt_overall, pred_overall\n",
    "\n",
    "#機械学習のアルゴリズムを指定。\n",
    "classifiers = {'FHMM':FHMM()}\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "#サンプルタイムの周期を指定します。周期が短いほど学習時間は長くなります。\n",
    "sample_period = 1\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(\"*\"*20)\n",
    "    print(clf_name)\n",
    "    print(\"*\" *20)\n",
    "    start = time.time()\n",
    "    # Note that we have given the sample period to downsample the data to 1 minute. \n",
    "    # If instead of top_5 we wanted to train on all appliance, we would write \n",
    "    # fhmm.train(train_elec, sample_period=60)\n",
    "    clf.train(train_elec.submeters(), sample_period=sample_period)\n",
    "    end = time.time()\n",
    "    print(\"Runtime =\", end-start, \"seconds.\")\n",
    "    gt, predictions[clf_name] = predict(clf, test_elec, sample_period, \"Asia/Tokyo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fb6bb",
   "metadata": {},
   "source": [
    "最後に学習モデルをテストデータに当てはめた結果を確認します。結果をCSVファイルに出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#最初の数行を確認\n",
    "appliance_labels = [m.label() for m in gt.columns.values]\n",
    "predictions['FHMM'].columns = appliance_labels\n",
    "predictions['FHMM'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分類結果を図示\n",
    "predictions['FHMM'].plot(label=\"Pred\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d140e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#合計の電力消費を図示\n",
    "test_elec.mains().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8aa558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSVファイルを出力\n",
    "df = predictions['FHMM']\n",
    "df.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d6ef8",
   "metadata": {},
   "source": [
    "他にも色々確認できる機能がありますが、確認したくなったらgithub( https://nilmtk.github.io/ )に色々情報が載っているので見てみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1801d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
